{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/monk/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# let's take one dataset for example\n",
    "from multilab.datasets import reuter\n",
    "sentences, labels = reuter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing preprocessing class\n",
    "# let's play with that\n",
    "\n",
    "from multilab.preprocess import Text_preprocessing\n",
    "text_preprocessing = Text_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentences and labels to dataframe with one hot\n",
    "\n",
    "dataframe = text_preprocessing.labels_to_dataframe(sentences,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acq</th>\n",
       "      <th>alum</th>\n",
       "      <th>barley</th>\n",
       "      <th>bop</th>\n",
       "      <th>carcass</th>\n",
       "      <th>castor-oil</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>coconut</th>\n",
       "      <th>coconut-oil</th>\n",
       "      <th>coffee</th>\n",
       "      <th>...</th>\n",
       "      <th>sunseed</th>\n",
       "      <th>tea</th>\n",
       "      <th>tin</th>\n",
       "      <th>trade</th>\n",
       "      <th>veg-oil</th>\n",
       "      <th>wheat</th>\n",
       "      <th>wpi</th>\n",
       "      <th>yen</th>\n",
       "      <th>zinc</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BAHIA COCOA REVIEW\\n  Showers continued throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPUTER TERMINAL SYSTEMS &amp;lt;CPML&gt; COMPLETES ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acq  alum  barley  bop  carcass  castor-oil  cocoa  coconut  coconut-oil  \\\n",
       "0    0     0       0    0        0           0      1        0            0   \n",
       "1    1     0       0    0        0           0      0        0            0   \n",
       "\n",
       "   coffee  ...  sunseed  tea  tin  trade  veg-oil  wheat  wpi  yen  zinc  \\\n",
       "0       0  ...        0    0    0      0        0      0    0    0     0   \n",
       "1       0  ...        0    0    0      0        0      0    0    0     0   \n",
       "\n",
       "                                                text  \n",
       "0  BAHIA COCOA REVIEW\\n  Showers continued throug...  \n",
       "1  COMPUTER TERMINAL SYSTEMS &lt;CPML> COMPLETES ...  \n",
       "\n",
       "[2 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10788/10788 [00:00<00:00, 65957.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1672 min 2 average 127.76279199110122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# let's check average length of sentences \n",
    "\n",
    "print(text_preprocessing.get_sentence_length(dataframe))\n",
    "\n",
    "#let's chuck all sentences upto 150 because avergae length is 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_case done\n",
      "punctuation removed\n",
      "text cleaning done\n"
     ]
    }
   ],
   "source": [
    "# let's do some initial preprocessing which include lowercase, remove html, remove special symbols\n",
    "\n",
    "# optional arguments : stop words, stemming, chunk values\n",
    "preprocessded_dataset = text_preprocessing.initial_preprocess(dataframe, chunk_value = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acq</th>\n",
       "      <th>alum</th>\n",
       "      <th>barley</th>\n",
       "      <th>bop</th>\n",
       "      <th>carcass</th>\n",
       "      <th>castor-oil</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>coconut</th>\n",
       "      <th>coconut-oil</th>\n",
       "      <th>coffee</th>\n",
       "      <th>...</th>\n",
       "      <th>sunseed</th>\n",
       "      <th>tea</th>\n",
       "      <th>tin</th>\n",
       "      <th>trade</th>\n",
       "      <th>veg-oil</th>\n",
       "      <th>wheat</th>\n",
       "      <th>wpi</th>\n",
       "      <th>yen</th>\n",
       "      <th>zinc</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bahia cocoa review showers continued throughou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>computer terminal systems ltcpml completes sal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acq  alum  barley  bop  carcass  castor-oil  cocoa  coconut  coconut-oil  \\\n",
       "0    0     0       0    0        0           0      1        0            0   \n",
       "1    1     0       0    0        0           0      0        0            0   \n",
       "\n",
       "   coffee  ...  sunseed  tea  tin  trade  veg-oil  wheat  wpi  yen  zinc  \\\n",
       "0       0  ...        0    0    0      0        0      0    0    0     0   \n",
       "1       0  ...        0    0    0      0        0      0    0    0     0   \n",
       "\n",
       "                                                text  \n",
       "0  bahia cocoa review showers continued throughou...  \n",
       "1  computer terminal systems ltcpml completes sal...  \n",
       "\n",
       "[2 rows x 91 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessded_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earn', 3964),\n",
       " ('acq', 2369),\n",
       " ('money-fx', 717),\n",
       " ('grain', 582),\n",
       " ('crude', 578),\n",
       " ('trade', 485),\n",
       " ('interest', 478),\n",
       " ('ship', 286),\n",
       " ('wheat', 283),\n",
       " ('corn', 237),\n",
       " ('dlr', 175),\n",
       " ('money-supply', 174),\n",
       " ('oilseed', 171),\n",
       " ('sugar', 162),\n",
       " ('coffee', 139),\n",
       " ('gnp', 136),\n",
       " ('gold', 124),\n",
       " ('veg-oil', 124),\n",
       " ('soybean', 111),\n",
       " ('bop', 105),\n",
       " ('nat-gas', 105),\n",
       " ('livestock', 99),\n",
       " ('cpi', 97),\n",
       " ('cocoa', 73),\n",
       " ('reserves', 73),\n",
       " ('carcass', 68),\n",
       " ('jobs', 67),\n",
       " ('copper', 65),\n",
       " ('cotton', 59),\n",
       " ('rice', 59),\n",
       " ('yen', 59),\n",
       " ('alum', 58),\n",
       " ('gas', 54),\n",
       " ('iron-steel', 54),\n",
       " ('ipi', 53),\n",
       " ('barley', 51),\n",
       " ('meal-feed', 49),\n",
       " ('rubber', 49),\n",
       " ('palm-oil', 40),\n",
       " ('sorghum', 34),\n",
       " ('zinc', 34),\n",
       " ('pet-chem', 32),\n",
       " ('tin', 30),\n",
       " ('lead', 29),\n",
       " ('silver', 29),\n",
       " ('wpi', 29),\n",
       " ('orange', 27),\n",
       " ('rapeseed', 27),\n",
       " ('strategic-metal', 27),\n",
       " ('soy-meal', 26),\n",
       " ('retail', 25),\n",
       " ('soy-oil', 25),\n",
       " ('fuel', 23),\n",
       " ('hog', 22),\n",
       " ('housing', 20),\n",
       " ('heat', 19),\n",
       " ('income', 16),\n",
       " ('lumber', 16),\n",
       " ('sunseed', 16),\n",
       " ('lei', 15),\n",
       " ('dmk', 14),\n",
       " ('oat', 14),\n",
       " ('tea', 13),\n",
       " ('platinum', 12),\n",
       " ('groundnut', 9),\n",
       " ('nickel', 9),\n",
       " ('l-cattle', 8),\n",
       " ('rape-oil', 8),\n",
       " ('coconut-oil', 7),\n",
       " ('sun-oil', 7),\n",
       " ('coconut', 6),\n",
       " ('instal-debt', 6),\n",
       " ('naphtha', 6),\n",
       " ('potato', 6),\n",
       " ('propane', 6),\n",
       " ('jet', 5),\n",
       " ('cpu', 4),\n",
       " ('nzdlr', 4),\n",
       " ('copra-cake', 3),\n",
       " ('cotton-oil', 3),\n",
       " ('dfl', 3),\n",
       " ('nkr', 3),\n",
       " ('palladium', 3),\n",
       " ('palmkernel', 3),\n",
       " ('rand', 3),\n",
       " ('castor-oil', 2),\n",
       " ('groundnut-oil', 2),\n",
       " ('lin-oil', 2),\n",
       " ('rye', 2),\n",
       " ('sun-meal', 2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset have 90 labels but if we don't want to use all the labels we can slice the dataset\n",
    "# based on labels \n",
    "\n",
    "# options to slice dataset : \n",
    "# keep_ratio = keep 25%, 50%, 75% or any % of dataset\n",
    "# freq_value = keep only those labels which are coming more than n ( ex: 10 ) times\n",
    "\n",
    "\n",
    "# let first get the frequency of dataset then slice\n",
    "\n",
    "dataset, frequency_list = text_preprocessing.keep_labels(preprocessded_dataset)\n",
    "frequency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acq', 2369),\n",
       " ('alum', 58),\n",
       " ('barley', 51),\n",
       " ('bop', 105),\n",
       " ('carcass', 68),\n",
       " ('cocoa', 73),\n",
       " ('coffee', 139),\n",
       " ('copper', 65),\n",
       " ('corn', 237),\n",
       " ('cotton', 59),\n",
       " ('cpi', 97),\n",
       " ('crude', 578),\n",
       " ('dlr', 175),\n",
       " ('dmk', 14),\n",
       " ('earn', 3964),\n",
       " ('fuel', 23),\n",
       " ('gas', 54),\n",
       " ('gnp', 136),\n",
       " ('gold', 124),\n",
       " ('grain', 582),\n",
       " ('heat', 19),\n",
       " ('hog', 22),\n",
       " ('housing', 20),\n",
       " ('income', 16),\n",
       " ('interest', 478),\n",
       " ('ipi', 53),\n",
       " ('iron-steel', 54),\n",
       " ('jobs', 67),\n",
       " ('lead', 29),\n",
       " ('lei', 15),\n",
       " ('livestock', 99),\n",
       " ('lumber', 16),\n",
       " ('meal-feed', 49),\n",
       " ('money-fx', 717),\n",
       " ('money-supply', 174),\n",
       " ('nat-gas', 105),\n",
       " ('oat', 14),\n",
       " ('oilseed', 171),\n",
       " ('orange', 27),\n",
       " ('palm-oil', 40),\n",
       " ('pet-chem', 32),\n",
       " ('platinum', 12),\n",
       " ('rapeseed', 27),\n",
       " ('reserves', 73),\n",
       " ('retail', 25),\n",
       " ('rice', 59),\n",
       " ('rubber', 49),\n",
       " ('ship', 286),\n",
       " ('silver', 29),\n",
       " ('sorghum', 34),\n",
       " ('soy-meal', 26),\n",
       " ('soy-oil', 25),\n",
       " ('soybean', 111),\n",
       " ('strategic-metal', 27),\n",
       " ('sugar', 162),\n",
       " ('sunseed', 16),\n",
       " ('tea', 13),\n",
       " ('tin', 30),\n",
       " ('trade', 485),\n",
       " ('veg-oil', 124),\n",
       " ('wheat', 283),\n",
       " ('wpi', 29),\n",
       " ('yen', 59),\n",
       " ('zinc', 34)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let say I want remove labels which are not coming more than 10 times in this dataset\n",
    "\n",
    "dataset_, frequency_list_ = text_preprocessing.keep_labels(preprocessded_dataset,\n",
    "                                                           freq_Value = 10)\n",
    "frequency_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acq', 2369),\n",
       " ('bop', 105),\n",
       " ('coffee', 139),\n",
       " ('corn', 237),\n",
       " ('crude', 578),\n",
       " ('dlr', 175),\n",
       " ('earn', 3964),\n",
       " ('gnp', 136),\n",
       " ('gold', 124),\n",
       " ('grain', 582),\n",
       " ('interest', 478),\n",
       " ('livestock', 99),\n",
       " ('money-fx', 717),\n",
       " ('money-supply', 174),\n",
       " ('nat-gas', 105),\n",
       " ('oilseed', 171),\n",
       " ('ship', 286),\n",
       " ('soybean', 111),\n",
       " ('sugar', 162),\n",
       " ('trade', 485),\n",
       " ('veg-oil', 124),\n",
       " ('wheat', 283)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another option let say I want to use only top 25% of labels from dataset\n",
    "\n",
    "dataset_s , frequency_list_s = text_preprocessing.keep_labels(preprocessded_dataset,\n",
    "                                                           keep_ratio=0.25)\n",
    "frequency_list_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't want to use full data then sample the data\n",
    "\n",
    "# options : \n",
    "# frac = % slice (ex 25% data)\n",
    "# value = value slice (ex 1200 samples only )\n",
    "\n",
    "slice_dataset = text_preprocessing.dataset_slice(dataset_s,ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2491/2491 [00:00<00:00, 69317.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the vocabulary frequency and then decide how many words you want to keep in vocab\n",
    "\n",
    "# options :\n",
    "# keep ration  = keep top 25%, 50%, 75% or any % vocab\n",
    "# freq_value   = keep only those words whose frequency is >= freq_value\n",
    "# custom_value = keep top n ( ex 1400 )  words \n",
    "\n",
    "# first checking the vocab freq : all arguments are false\n",
    "sorted_long, freq_num, word_to_int, int_to_word  = text_preprocessing.vocab_freq(slice_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 9674), ('of', 5669), ('to', 5203), ('in', 4128), ('mln', 3967), ('said', 3956), ('and', 3884), ('a', 3774), ('vs', 3734), ('dlrs', 2399)]\n",
      "13777\n"
     ]
    }
   ],
   "source": [
    "print(sorted_long[:10])\n",
    "print(len(sorted_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2491/2491 [00:00<00:00, 63894.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# or use top 25% words\n",
    "top_words, freq_lis, w2i, i2w = text_preprocessing.vocab_freq(slice_dataset,keep_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3444"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2491/2491 [00:00<00:00, 85572.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# or use only those words whose frequency is more than 12\n",
    "freq_words, fre_li , w2_i, i_2w = text_preprocessing.vocab_freq(slice_dataset,freq_Value=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735\n",
      "[('a', 3774), ('ab', 12), ('able', 19), ('about', 424), ('above', 51), ('accept', 13), ('accepted', 25), ('accord', 65), ('according', 51), ('account', 59)]\n"
     ]
    }
   ],
   "source": [
    "print(len(freq_words))\n",
    "print(freq_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2491/2491 [00:01<00:00, 1894.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# let's encode the sentences \n",
    "\n",
    "all_sentence_s, all_label_s, vocab_dict = text_preprocessing.encoder(slice_dataset,w2_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2491 2491 1737\n",
      "[582, 398, 1707, 1, 1717, 953, 456, 1562, 582, 680, 715, 309, 1, 1, 1, 1704, 1107, 953, 456, 611, 1562, 530, 352, 1, 1, 217, 1026, 1, 775, 744, 1623, 1562, 52, 1252, 743, 1178, 176, 1562, 1618, 308, 2, 1477, 224, 582, 1280, 224, 805, 1, 1032, 1348, 1695, 1, 83, 1562, 52, 1728, 743, 997, 1734, 800, 1348, 1045, 1561, 1562, 1170, 1718, 156, 743, 534, 1026, 953, 456, 582, 1348, 1562, 398, 796, 1501, 1582, 52, 1043, 1397, 1, 1026, 1562, 342, 82, 991, 669, 1, 800, 1348, 1562, 398, 1718, 1, 1, 1, 1, 5, 1115, 743, 501, 530, 307, 362, 1138, 563, 82, 299, 1056, 743, 1070, 487, 1479, 1562, 1, 697, 2, 239, 1582, 1187, 1562, 524, 1026, 953, 1591, 1026, 1, 743, 1, 82, 1, 2, 1723, 1063, 5, 1044, 1570, 1026, 487, 1193, 631, 5, 953, 1591, 1026, 257, 582, 1348]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_sentences),len(all_sentences),len(vocab_dict))\n",
    "print(all_sentences[1])\n",
    "print(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use tf-idf\n",
    "\n",
    "all_sentences, all_labels = text_preprocessing.tf_idf(slice_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2491x234879 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 479283 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737\n",
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1737/1737 [00:00<00:00, 232800.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# vocab embedding\n",
    "\n",
    "path_of_glove_embedding = 'glove.6B.300d.txt'\n",
    "\n",
    "# out of vocab words are encoded with 'unk' vectors\n",
    "print(len(vocab_dict))\n",
    "vocab, out_of_vocab_words = text_preprocessing.vocab_embedding(vocab_dict, path_of_glove_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1737, 300)\n",
      "['carryforward', 'carryforwards', 'chemlawn', 'dlrsbbl', 'dlrsshr', 'fiveyear', 'incs', 'ltxon', 'mths', 'qtly', 'qtrly', 'shortterm', 'shrs', 'sosnoff', 'stateowned', 'taxfree', 'threefortwo', 'twoforone', 'whollyowned', 'yearago']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.shape)\n",
    "print(out_of_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "# options : test value : defalt : 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = text_preprocessing.split_dataset(all_sentence_s, all_label_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743 748 1743 748\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
