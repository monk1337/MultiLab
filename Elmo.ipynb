{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/monk/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "lower_case done\n",
      "punctuation removed\n",
      "text cleaning done\n"
     ]
    }
   ],
   "source": [
    "# let's take one dataset for example\n",
    "from multilab.datasets import reuter\n",
    "sentences, labels = reuter()\n",
    "\n",
    "from multilab.preprocess import Text_preprocessing\n",
    "text_preprocessing = Text_preprocessing()\n",
    "\n",
    "dataframe = text_preprocessing.labels_to_dataframe(sentences,labels)\n",
    "preprocessded_dataset = text_preprocessing.initial_preprocess(dataframe, chunk_value = 25)\n",
    "dataset, frequency_list = text_preprocessing.keep_labels(preprocessded_dataset,keep_ratio=0.10)\n",
    "slice_dataset = text_preprocessing.dataset_slice(dataset,ratio=0.25)\n",
    "\n",
    "import numpy as np\n",
    "all_sente = list(slice_dataset['text'])\n",
    "all_label = np.array(slice_dataset.drop('text', 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = text_preprocessing.split_dataset(all_sente, all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilab.models import Elmo\n",
    "\n",
    "config = {\n",
    "                         'no_of_labels'               : len(y_train[0]),\n",
    "                         'learning_rate'              : 0.001,\n",
    "                         'epoch'                      : 2,\n",
    "                         'batch_size'                 : 128,\n",
    "                         'result_path'                : '/Users/monk/Desktop'\n",
    "                        }\n",
    "\n",
    "\n",
    "el_m = Elmo(X_train, y_train, X_test,  y_test, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(el_m.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "\n",
    "ins = tf.placeholder(tf.string, (None), name='pl_phrase_text')\n",
    "\n",
    "\n",
    "module = hub.Module('https://tfhub.dev/google/elmo/2', trainable=True)\n",
    "embeddings = module(dict(text=ins))\n",
    "embeddings = tf.expand_dims(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    print(sess.run(embeddings,feed_dict={ins:['hello']}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-a600ef760fca>:18: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-a600ef760fca>:18: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-a600ef760fca>:25: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-a600ef760fca>:25: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/monk/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tokens = tf.placeholder(tf.string, (None), name='pl_phrase_text')\n",
    "pl_phrase_len = tf.placeholder(tf.int32, (None), name='pl_phrase_len')\n",
    "\n",
    "tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "                [\"dogs\", \"are\", \"in\", \"the\", \"fog\", \"\"]]\n",
    "tokens_length = [6, 5]\n",
    "\n",
    "\n",
    "module = hub.Module('https://tfhub.dev/google/elmo/2', trainable=True)\n",
    "module_features = module(dict(tokens=tokens, sequence_len = pl_phrase_len),\n",
    "                                 signature='tokens', as_dict=True)\n",
    "embeddingse = module_features[\"elmo\"]\n",
    "\n",
    "with tf.variable_scope('Layer1'):\n",
    "    cell_fw1 = tf.nn.rnn_cell.LSTMCell(num_units=128, state_is_tuple=True)\n",
    "    cell_bw1 = tf.nn.rnn_cell.LSTMCell(num_units=128, state_is_tuple=True)\n",
    "\n",
    "    outputs1, states1 = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=cell_fw1,\n",
    "        cell_bw=cell_bw1,\n",
    "        inputs=embeddingse,\n",
    "        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    out, data,t = sess.run([outputs1,embeddingse,module_features],feed_dict={tokens: tokens_input, pl_phrase_len: tokens_length})\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output = tf.reshape(outputs1[0], (-1, 128))\n",
    "rnn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_outputs = tf.reshape(outputs1[0], (-1, 128 * 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(768)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "# padded_sequence = [i + [0] * (max_sequence - len(i)) if len(i) < max_sequence else i for i in batch_data_j]\n",
    "\n",
    "\n",
    "sentences = ['check this out','i am very happy', 'what is', ['check','this'],'he a a a abs']\n",
    "\n",
    "\n",
    "def pad_sentences(self, sentences, sequence_len):\n",
    "    padded_sentences = []\n",
    "    actual_length    = []\n",
    "\n",
    "\n",
    "    for sentence in tqdm(sentences):\n",
    "        if not isinstance(sentence, list):\n",
    "            token = nltk.word_tokenize(sentence)\n",
    "        else:\n",
    "            token = sentence\n",
    "        \n",
    "        if len(token) < sequene_len:\n",
    "            actual_length.append(len(token))\n",
    "            token = token + [''] * (sequene_len-len(token))\n",
    "        else:\n",
    "            actual_length.append(len(token))\n",
    "        \n",
    "        padded_sentences.append(token)\n",
    "    return padded_sentences, actual_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1920.12it/s]\n"
     ]
    }
   ],
   "source": [
    "chy = pad_sentences(sentences,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['check', 'this', 'out', '', ''],\n",
       "  ['i', 'am', 'very', 'happy', ''],\n",
       "  ['what', 'is', '', '', ''],\n",
       "  ['check', 'this', '', '', ''],\n",
       "  ['he', 'a', 'a', 'a', 'abs']],\n",
       " [3, 4, 2, 2, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_len = []\n",
    "for m in chy[0]:\n",
    "    actu = [k for k in m if k!='']\n",
    "    actual_len.append(len(actu))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def actual_len(list_data):\n",
    "    \n",
    "    actual_ = []\n",
    "    for sequence in list_data:\n",
    "        actual = [sub_ for sub_ in sequence if sub_!='']\n",
    "        actual_.append(len(actual))\n",
    "    return actual_\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data        = actual_len(chy[0])\n",
    "second_list = actual_len(chy[0])\n",
    "data.extend(second_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 2, 2, 5, 3, 4, 2, 2, 5]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
