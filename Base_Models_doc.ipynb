{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/monk/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# let's take one dataset for example\n",
    "from multilab.datasets import reuter\n",
    "sentences, labels = reuter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_case done\n",
      "punctuation removed\n",
      "text cleaning done\n"
     ]
    }
   ],
   "source": [
    "# very few datapoints just to demonstrate how to use models\n",
    "\n",
    "# preprocessing\n",
    "from multilab.preprocess import Text_preprocessing\n",
    "text_preprocessing = Text_preprocessing()\n",
    "dataframe = text_preprocessing.labels_to_dataframe(sentences,labels)\n",
    "preprocessded_dataset = text_preprocessing.initial_preprocess(dataframe, chunk_value = 5)\n",
    "dataset_s , frequency_list_s = text_preprocessing.keep_labels(preprocessded_dataset,\n",
    "                                                           keep_ratio=0.1)\n",
    "\n",
    "# text preprocessing\n",
    "slice_dataset = text_preprocessing.dataset_slice(dataset_s,ratio=0.01)\n",
    "\n",
    "#tf-idf\n",
    "all_sentences, all_labels = text_preprocessing.tf_idf(slice_dataset)\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = text_preprocessing.split_dataset(all_sentences, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4444444444444444, 'f1_score': 0.38383838383838387}\n"
     ]
    }
   ],
   "source": [
    "from multilab.models import BinaryRe\n",
    "Bm = BinaryRe(X_train, y_train, X_test,y_test)\n",
    "print(Bm.train())\n",
    "\n",
    "# four base models\n",
    "\n",
    "# BinaryRelevance\n",
    "# ClassifierChain\n",
    "# LabelPowerset\n",
    "# Mlknn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5185185185185185, 'f1_score': 0.5357142857142857}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from multilab.models import Classfierchains\n",
    "Cc = Classfierchains(X_train, y_train, X_test,y_test)\n",
    "print(Cc.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5185185185185185, 'f1_score': 0.5357142857142857}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/monk/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from multilab.models import labelpowerset\n",
    "lp = labelpowerset(X_train, y_train, X_test,y_test)\n",
    "print(lp.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eabb8202f196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhamming_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBilstm_simples\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hm'"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import pickle as pk\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from hm import hamming_score\n",
    "from sklearn.metrics import f1_score\n",
    "from Bilstm_simples import Base_model\n",
    "\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os \n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load configuation\n",
    "\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('config.properties')\n",
    "parameter_dict = dict(config.items('BiLstm network'))\n",
    "boolean_dict = {'None': None, 'True': True, 'False': False}\n",
    "\n",
    "#load data files \n",
    "with open(parameter_dict['sentence_path'] ,'rb') as f:\n",
    "    X_data = pk.load(f)\n",
    "\n",
    "with open(parameter_dict['labels_path']   ,'rb') as f:\n",
    "    y_data = pk.load(f)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, train_size=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_train_data(batch_size, slice_no):\n",
    "\n",
    "\n",
    "    batch_data_j = np.array(X_train[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "    batch_labels = np.array(y_train[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "    \n",
    "    max_sequence = max(list(map(len, batch_data_j)))\n",
    "\n",
    "    # getting Max length of sequence\n",
    "    padded_sequence = [i + [0] * (max_sequence - len(i)) if len(i) < max_sequence else i for i in batch_data_j]\n",
    "    \n",
    "    return {'sentenc': padded_sequence, 'labels': batch_labels}\n",
    "\n",
    "\n",
    "def get_test_data(batch_size,slice_no):\n",
    "\n",
    "\n",
    "    batch_data_j = np.array(X_val[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "    batch_labels = np.array(y_val[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "    \n",
    "    max_sequence = max(list(map(len, batch_data_j)))\n",
    "    \n",
    "    padded_sequence = [i + [0] * (max_sequence - len(i)) if len(i) < max_sequence else i for i in batch_data_j]\n",
    "    \n",
    "    return {'sentenc': padded_sequence, 'labels': batch_labels}\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_(model, epoch_, batch_size = 120):\n",
    "\n",
    "    sess = tf.get_default_session()\n",
    "    iteration = len(X_val) // batch_size\n",
    "\n",
    "    sub_accuracy    = []\n",
    "    hamming_score_a = []\n",
    "    hamming_loss_   = []\n",
    "\n",
    "    micr_ac = []\n",
    "    weight_ac = []\n",
    "\n",
    "    for i in range(iteration):\n",
    "        \n",
    "        data_g = get_test_data(batch_size,i)\n",
    "        \n",
    "        sentences_data = data_g['sentenc']\n",
    "        labels_data    = data_g['labels']\n",
    "\n",
    "        network_out, targe = sess.run([model.predictions,model.targets], feed_dict={model.placeholders['sentence']: sentences_data,\n",
    "                                                                                    model.placeholders['labels']: labels_data, \n",
    "                                                                                    model.placeholders['dropout']: 0.0})\n",
    "\n",
    "        h_s     = hamming_score(targe, network_out)\n",
    "\n",
    "        ham_sco = h_s['hamming_score']\n",
    "        sub_acc = h_s['subset_accuracy']\n",
    "        ham_los = h_s['hamming_loss']\n",
    "\n",
    "        sub_accuracy.append(sub_acc)\n",
    "        hamming_score_a.append(ham_sco)\n",
    "        hamming_loss_.append(ham_los)\n",
    "\n",
    "\n",
    "\n",
    "        micr_ac.append(f1_score(targe, network_out, average='micro'))\n",
    "        weight_ac.append(f1_score(targe, network_out, average='weighted'))\n",
    "\n",
    "    return {  'subset_accuracy' : np.mean(np.array(sub_accuracy)) , \n",
    "              'hamming_score'   : np.mean(np.array(hamming_score_a)) , \n",
    "              'hamming_loss'    : np.mean(np.array(hamming_loss_)), \n",
    "               'micro_ac'       : np.mean(np.array(micr_ac)), \n",
    "               'weight_ac'      : np.mean(np.array(weight_ac)) , 'epoch': epoch_ }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, batch_size = int(parameter_dict['batch_size']), epoch = int(parameter_dict['epoch'])):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        iteration = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "        for i in range(epoch):\n",
    "            t = trange(iteration, desc='Bar desc', leave=True)\n",
    "\n",
    "            for j in t:\n",
    "\n",
    "\n",
    "\n",
    "                data_g = get_train_data(batch_size,j)\n",
    "                sentences_data = data_g['sentenc']\n",
    "                labels_data    = data_g['labels']\n",
    "\n",
    "\n",
    "\n",
    "                network_out, train, targe, losss  = sess.run([model.predictions, model.optimizer, model.targets,model.loss],\n",
    "                                          feed_dict={model.placeholders['sentence']: sentences_data,\n",
    "                                                     model.placeholders['labels']: labels_data,\n",
    "                                                     model.placeholders['dropout']: 0.2})\n",
    "\n",
    "                t.set_description(\"epoch {},  iteration {},  F1_score {},  loss {}\".format(i,\n",
    "                                                                                       j,\n",
    "                                                                                       f1_score(targe, \n",
    "                                                                                                network_out, \n",
    "                                                                                                average='micro'), \n",
    "                                                                                       losss))\n",
    "                t.refresh() # to show immediately the update\n",
    "\n",
    "\n",
    "            val_data = evaluate_(model, i, batch_size = 100)\n",
    "            print(\"validation_acc\",val_data)\n",
    "            with open('./result/iterres.txt', 'a') as f:\n",
    "                f.write(str({'test_accuracy':  val_data}) + '\\n')\n",
    "                \n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    model = Base_model(vocab_size                  =   int(parameter_dict['vocab_size']),\n",
    "                       rnn_units                   =   int(parameter_dict['rnn_units']), \n",
    "                       word_embedding_dim          =   int(parameter_dict['word_embedding_dim']),  \n",
    "                       no_of_labels                =   int(parameter_dict['no_of_labels']), \n",
    "                       learning_rate               =   float(parameter_dict['learning_rate']),   \n",
    "                       trained_embedding           =   boolean_dict[parameter_dict['trained_embedding']], \n",
    "                       train_embedding             =   boolean_dict[parameter_dict['train_embedding']],\n",
    "                       model_output                =   boolean_dict[parameter_dict['model_output']])\n",
    "    \n",
    "    train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Bilstm(object):\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, configuration = None):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test  = X_test\n",
    "        self.y_test  = y_test\n",
    "        \n",
    "        self.old_configuration = {\n",
    "                         'vocab_size'                 : 2000, \n",
    "                         'rnn_units'                  : 256, \n",
    "                         'word_embedding_dim'         : 300, \n",
    "                         'learning_rate'              : 0.001, \n",
    "                         'pretrained_embedding_matrix': None,\n",
    "                         'dropout'                    : 0.2,\n",
    "                         'epoch'                      : 1,\n",
    "                         'batch_size'                 : 128,\n",
    "                         'result_path'                : '/Users/monk/Desktop/'\n",
    "                        }\n",
    "        \n",
    "        if configuration:\n",
    "            self.old_configuration.update(configuration)\n",
    "            \n",
    "        if self.old_configuration['pretrained_embedding_matrix'] is None:\n",
    "            self.old_configuration['pretrained_embedding_matrix'] = None\n",
    "        else:\n",
    "            with open(self.old_configuration['pretrained_embedding_matrix'], 'rb') as f:\n",
    "                self.embedding_mat = np.array(pk.load(f))\n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "    def default_configuration(self):\n",
    "        \n",
    "        default_conf = {\n",
    "                        'vocab_size'      : 'vocab_size of corpus', \n",
    "                        'rnn_unit'        : 'bi-directional_rnn units', \n",
    "                        'embedding_dim'   : 'word_embedding_dim', \n",
    "                        'learning rate'   : 'learning rate of model', \n",
    "                        'embedding_matrix': 'path of embedded matrix  (ex glove, elmo )',\n",
    "                        'train_embedding' : 'train glove embedding or not', \n",
    "                        'last_output'     : 'use lstm last state or use final output of all states'\n",
    "                       }\n",
    "        return default_conf\n",
    "    \n",
    "    \n",
    "    # train data loader\n",
    "    def get_train_data(self, batch_size, slice_no):\n",
    "\n",
    "\n",
    "        batch_data_j = np.array(X_train[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "        batch_labels = np.array(y_train[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "\n",
    "        max_sequence = max(list(map(len, batch_data_j)))\n",
    "\n",
    "        # getting Max length of sequence\n",
    "        padded_sequence = [i + [0] * (max_sequence - len(i)) if len(i) < max_sequence else i for i in batch_data_j]\n",
    "\n",
    "        return {'sentenc': padded_sequence, 'labels': batch_labels }\n",
    "    \n",
    "    \n",
    "    # test data loader\n",
    "    def get_test_data(self, batch_size,slice_no):\n",
    "\n",
    "\n",
    "        batch_data_j = np.array(X_val[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "        batch_labels = np.array(y_val[slice_no * batch_size:(slice_no + 1) * batch_size])\n",
    "\n",
    "        max_sequence = max(list(map(len, batch_data_j)))\n",
    "\n",
    "        padded_sequence = [i + [0] * (max_sequence - len(i)) if len(i) < max_sequence else i for i in batch_data_j]\n",
    "\n",
    "        return {'sentenc': padded_sequence, 'labels': batch_labels}\n",
    "    \n",
    "    \n",
    "    def evaluate_(self, model, epoch_, batch_size = 120):\n",
    "\n",
    "        sess = tf.get_default_session()\n",
    "        iteration = len(X_val) // batch_size\n",
    "\n",
    "        sub_accuracy    = []\n",
    "        hamming_score_a = []\n",
    "        hamming_loss_   = []\n",
    "\n",
    "        micr_ac = []\n",
    "        weight_ac = []\n",
    "\n",
    "        for i in range(iteration):\n",
    "\n",
    "            data_g = self.get_test_data(batch_size,i)\n",
    "\n",
    "            sentences_data = data_g['sentenc']\n",
    "            labels_data    = data_g['labels']\n",
    "\n",
    "            network_out, targe = sess.run([model.predictions,model.targets], feed_dict={model.placeholders['sentence']: sentences_data,\n",
    "                                                                                        model.placeholders['labels']: labels_data, \n",
    "                                                                                        model.placeholders['dropout']: 0.0})\n",
    "\n",
    "            h_s     = hamming_score(targe, network_out)\n",
    "\n",
    "            ham_sco = h_s['hamming_score']\n",
    "            sub_acc = h_s['subset_accuracy']\n",
    "            ham_los = h_s['hamming_loss']\n",
    "\n",
    "            sub_accuracy.append(sub_acc)\n",
    "            hamming_score_a.append(ham_sco)\n",
    "            hamming_loss_.append(ham_los)\n",
    "\n",
    "\n",
    "\n",
    "            micr_ac.append(f1_score(targe, network_out, average='micro'))\n",
    "            weight_ac.append(f1_score(targe, network_out, average='weighted'))\n",
    "\n",
    "        return {  'subset_accuracy' : np.mean(np.array(sub_accuracy)) , \n",
    "                  'hamming_score'   : np.mean(np.array(hamming_score_a)) , \n",
    "                  'hamming_loss'    : np.mean(np.array(hamming_loss_)), \n",
    "                   'micro_ac'       : np.mean(np.array(micr_ac)), \n",
    "                   'weight_ac'      : np.mean(np.array(weight_ac)) , 'epoch': epoch_ }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_model(model, batch_size = int(self.old_configuration['batch_size']), epoch = int(self.old_configuration['epoch'])):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            iteration = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "            for i in range(epoch):\n",
    "                t = trange(iteration, desc='Bar desc', leave=True)\n",
    "\n",
    "                for j in t:\n",
    "\n",
    "\n",
    "\n",
    "                    data_g = get_train_data(batch_size,j)\n",
    "                    sentences_data = data_g['sentenc']\n",
    "                    labels_data    = data_g['labels']\n",
    "\n",
    "\n",
    "\n",
    "                    network_out, train, targe, losss  = sess.run([model.predictions, model.optimizer, model.targets,model.loss],\n",
    "                                              feed_dict={model.placeholders['sentence']: sentences_data,\n",
    "                                                         model.placeholders['labels']: labels_data,\n",
    "                                                         model.placeholders['dropout']: 0.2})\n",
    "\n",
    "                    t.set_description(\"epoch {},  iteration {},  F1_score {},  loss {}\".format(i,\n",
    "                                                                                           j,\n",
    "                                                                                           f1_score(targe, \n",
    "                                                                                                    network_out, \n",
    "                                                                                                    average='micro'), \n",
    "                                                                                           losss))\n",
    "                    t.refresh() # to show immediately the update\n",
    "\n",
    "\n",
    "                val_data = evaluate_(model, i, batch_size = 100)\n",
    "                print(\"validation_acc\",val_data)\n",
    "                with open(self.old_configuration['result_path'], 'a') as f:\n",
    "                    f.write(str({'test_accuracy':  val_data}) + '\\n')\n",
    "                    \n",
    "        \n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.96749427 8.37410883 8.93786136 4.858598   4.23367702 3.90523282\n",
      "  6.90688789 6.73677213 9.21940306 9.6061811  1.76435984 3.11601394\n",
      "  3.609397   6.99067604 8.11557778 3.78312029 1.32424771 6.99604939\n",
      "  6.26806372 8.84764374 1.52276249 4.37953128 8.96641546 5.82352097\n",
      "  4.24953579 1.76626568 6.74539449 4.05552095 1.32276495 5.84345404\n",
      "  9.47571667 9.09332491 9.66537468 5.31360579]\n",
      " [5.0965566  2.89707967 4.42813393 6.47907003 8.26568389 9.35974264\n",
      "  5.94795408 9.57289163 8.22587112 3.48316327 6.74307239 2.03558089\n",
      "  2.6252177  6.97514451 6.11062897 1.05484058 4.01252538 1.88531099\n",
      "  7.58288896 8.33064739 1.30870082 0.23070554 8.05773683 1.63856073\n",
      "  2.50701087 4.33130697 6.34362772 5.82573735 7.27797961 7.86481944\n",
      "  8.75459193 8.58835285 7.81609895 8.77164648]\n",
      " [0.75212823 9.99761552 9.62505458 3.35114296 1.2840918  1.82157585\n",
      "  8.77775895 8.56732858 8.02259777 0.33052952 7.55428328 0.92367731\n",
      "  4.67996352 9.16923802 1.05494592 0.90791769 7.62663702 3.88363306\n",
      "  7.44629013 7.9900496  5.8634585  6.17737301 0.58768218 3.73308978\n",
      "  4.02532003 4.916376   6.88814078 7.37155309 6.54585129 9.98676434\n",
      "  1.52387744 8.96407946 0.33588187 7.28998767]\n",
      " [2.43166068 6.53242733 2.38678341 4.03783784 5.59341276 7.1451251\n",
      "  2.36461714 4.56665551 5.87165406 1.66430646 0.50456323 9.51330451\n",
      "  5.95648821 9.75767943 1.24044439 5.62728834 6.95075118 5.69072115\n",
      "  6.99063061 6.74568564 9.21116554 7.08987895 2.71882467 9.26644635\n",
      "  7.29966787 7.63007603 5.15469627 9.09796533 1.21397146 3.26934533\n",
      "  8.4458578  6.04943395 4.25865211 5.0985138 ]\n",
      " [5.45668975 1.93817764 4.88298884 9.02187333 0.69539517 4.97340527\n",
      "  0.26169059 4.39597189 5.42384196 4.69844667 5.37928124 9.48551802\n",
      "  9.43314323 8.20824118 8.24545811 4.95292219 9.90740024 2.21674683\n",
      "  3.78427142 4.88110353 3.06392527 9.81991781 1.76437329 6.74815493\n",
      "  5.64638591 4.8704727  4.03324262 1.11861467 8.89847265 7.01104776\n",
      "  4.96358089 5.84257362 2.43919377 3.02957056]\n",
      " [6.85948508 8.76834779 6.77957734 2.26214168 0.97362727 5.29120198\n",
      "  6.07915684 3.80658152 6.0952034  0.3818186  4.2104619  7.12651001\n",
      "  8.38912607 3.99148121 4.27787826 1.18567905 0.336974   3.43130283\n",
      "  3.78767385 9.91794369 2.16719783 0.34876173 0.56642816 7.5121614\n",
      "  7.40270626 2.48827618 2.76981752 9.28239349 0.13292433 5.47090436\n",
      "  0.53457767 4.88782442 9.17747376 2.28632756]\n",
      " [9.81195634 2.43073571 8.43591944 4.6622483  7.53070052 2.46523162\n",
      "  9.56952698 5.07770844 0.71530784 1.54381478 1.87151171 7.48195016\n",
      "  6.51286399 2.98243424 9.3483422  9.33393486 2.73586786 1.59665628\n",
      "  7.30493325 0.82280898 2.57707323 8.88426668 5.66669084 9.29331873\n",
      "  4.38394075 3.87260995 4.98419633 0.2522777  5.49508298 3.96985624\n",
      "  0.58455077 2.39228679 0.29964393 4.89962423]\n",
      " [7.72488937 9.92991793 2.13286638 3.26011665 2.20045999 8.53025178\n",
      "  6.01280016 1.3628028  2.66980651 4.24678899 2.07458584 7.97493426\n",
      "  0.90137664 8.5813736  7.54209164 5.06690494 6.0864316  0.93391407\n",
      "  8.98560093 1.90783722 8.39794564 7.61160149 7.26391624 2.73884254\n",
      "  9.15763542 1.811153   8.97795287 6.96933067 3.44801914 8.85350612\n",
      "  3.02829191 1.85702814 1.44762736 0.9789783 ]\n",
      " [8.19964648 1.48350628 4.93746581 2.08425551 7.84237934 3.45141053\n",
      "  1.09494601 8.9139688  1.61421446 3.71293238 9.52227888 1.90148182\n",
      "  0.65781996 0.45655193 4.56720197 9.92842051 1.23873843 0.40585892\n",
      "  8.83354625 5.20880068 8.11512614 9.94814055 0.43330949 7.37287959\n",
      "  9.35907035 7.26054079 9.75163102 6.63203779 5.4980662  2.41379198\n",
      "  6.14244047 6.82609629 6.77735304 4.77926626]\n",
      " [6.00543081 2.99282708 3.65371249 5.65438526 0.65227539 9.49296848\n",
      "  3.24779068 2.93589347 5.57835361 8.1840691  5.45984206 1.84792733\n",
      "  1.34934319 9.97907602 7.45815937 2.57197764 8.57319353 7.76437119\n",
      "  4.4897148  4.33635965 4.65226319 8.93259967 2.39513649 0.73826303\n",
      "  6.19919876 2.50793498 2.02602156 9.00723259 3.58013542 8.55921138\n",
      "  1.65609546 6.59707459 2.05579707 1.69563266]\n",
      " [0.67332476 0.87510899 7.93106118 1.04148421 5.18500878 9.26573266\n",
      "  3.55615362 7.0888449  0.19471629 5.67896443 2.12411526 9.59036153\n",
      "  4.99611155 9.93740766 5.36106355 1.73514337 3.82754326 4.0343372\n",
      "  4.89901983 5.54173539 5.8225801  0.57982678 6.02341956 0.61770357\n",
      "  8.08153776 6.98704877 4.82051612 0.3349242  6.04714274 6.67830426\n",
      "  9.39848663 8.41784828 5.32059384 0.99150402]\n",
      " [1.53271992 0.89592765 5.9755574  0.47586659 7.03821799 5.49398876\n",
      "  8.07885868 7.47725118 7.79764392 6.91139197 8.65478747 8.22562687\n",
      "  4.33957829 1.16896504 5.79950651 3.14304098 0.15400135 5.45745034\n",
      "  7.11680063 2.33034309 9.06407276 9.21966591 5.7491333  6.80407591\n",
      "  4.70452865 2.59942241 3.70055025 1.71426986 1.7568359  3.41665458\n",
      "  9.94978019 6.92483529 5.17215189 4.74969497]]\n"
     ]
    }
   ],
   "source": [
    "a = {'a':1,'b':2,'c':3}\n",
    "\n",
    "npo = np.random.uniform(0,10,[12,34])\n",
    "cus = None\n",
    "\n",
    "if npo is None:\n",
    "    npo = None\n",
    "else:\n",
    "    print(npo)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
